\documentclass[11pt,twoside,a4paper]{article}
\usepackage{a4wide,amsmath,amssymb}
% \usepackage[ngerman]{babel}
\usepackage[utf8x]{inputenc}
\hyphenation{}

% Build pdf:
% $ pdflatex seminar_template.tex
% $ pdflatex seminar_template.tex
% Run pdflatex twice to get the references right...


%-------------------------- Formatting --------------------------%

% Picture and table title formats
\usepackage[bf,small]{caption}

\usepackage{enumitem}
\usepackage{listings}
\usepackage{longtable}

%\usepackage{mathpazo}  % -- use Palatino --
%\usepackage{mathptmx}  % -- or Times --

% Use this to discern DRAFTs from final versions
%\usepackage{draftcopy}
%\draftcopySetGrey{0.90}   %   90% = very light grey
%\draftcopySetScale{1}

%--------------- line and paragraph distances ----------------------%
\setlength{\parindent}{0em}
\setlength{\parskip}{\medskipamount}    % distance between paragraphs

% correctly format URLs and email addresses
\usepackage{url}
% example for email addresses: \url{foo@bar.com}

% Tools for note taking, ideas...
\newcommand{\notesubsection}[1][unsorted idea]{%
\subsection*{#1}%
\addcontentsline{toc}{subsection}{#1}%
}

% side note:
\newcommand{\bemerkung}[1]{\marginpar{\small\textsl{\textsf{#1}}}}

% this adds a little "under construction" icon on the side
%
% For this to work you need an "Baustelle.eps" icon. Get it from here:
%  http://www.net.in.tum.de/teaching/WS04/routing/Baustelle.eps.gz
\newcommand{\baustelle}[1][]{
 \marginpar{%
   \centerline{\includegraphics[scale=0.3]{Baustelle.eps}}
   {\small\textsl{\textsf{\raggedright #1}}}
}}

\begin{document}

\title{Weird Machines}
\author{Federico Scrinzi \\
  (\texttt{federico.scrinzi@campus.tu-berlin.de})\\[5mm]
  "`Computer Security Seminar"' , \\
  Technische Universität Berlin
}
  
\date{WS\,2013/2014 (Version of \today)}

\maketitle

\abstract{
What are exploits in fact? It is possible to define them as programs that run on an unanticipated computational structure, performing unexpected computation. Buffer overflows, format string overflows or SQL injections are just some classical examples of vulnerabilities that allow to achieve this goal. It is possible to see exploits for this flaws as input data used as bytecode on some kind of virtual machine. We will call this class of peculiar VMs "Weird machines".

Unexpected computation means not only the execution of unintended instructions on the CPU but can be achieved also using Turing complete machines hidden in the target. This paper will present two examples of weird machines: the first based on ABI metadata while the second on the MMU.
}


\section{Introduction}
Exploits are a proof-by-construction of unexpected computation. Through an exploit, what an attacker wants usually to achieve is to make the target machine do something that was not anticipated. Classically this means deceiving the system into executing arbitrary code, but we will see that modern systems offer many different hidden ways of achieving computation.

In the last decade there was a major change in security analysis regarding this aspect: the threat model needed to be extended from a simplistic approach based on "malicious code" to a more comprehensive one based on "malicious computation". \cite{hund}
The classic paper "Smashing the Stack for Fun and Profit" by Aleph One \cite{smashing} illustrates one of the first steps in the conversion of an input data flow into altered program control flow. Thus, not only code but also data may be a potential threat: data processing changes the state of the machine analyzing it, thus one could think of specially crafted inputs as a possible way to achieve computation.

Modern systems hide a plethora of weird machines that might be exploited, the new goal for security analysts is to find them.   Turing-complete machines are hidden in many systems: CSS3 combined with HTML \cite{}, C++ templates \cite{} or the Game of Life are proven to satisfy those properties. These are just a few examples of machines driven by what is not normally considered as executable code.

Therefore, security research's core subjects of study-trust and trustworthiness in computing systems are now faced with new questions, such as "What execution paths can programs be trusted to not take under any circumstances, no matter what the inputs?" or "Which properties of inputs can a particular security system verify, and which are beyond its limits?". \cite{bratus}

Exploits based on weird machines are harder to detect than classical ones and hidden, unexpected computation can be a really dangerous threat. For that reason higher and higher consideration should be given to the study of this field, to reveal new potential hazard and build more secure systems.


\section{Weird machine \#1: ELF metadata construction}

This section summarizes the work done by R. Shapiro, S. Bratus and S. W. Smith \cite{elf_machine} in building a weird machine that exploits ELF relocation metadata to do computation.

\subsection{Introduction to ELF}
The Executable and Linkable Format (ELF) is a file format for object code, executables and shared libraries commonly used in many Unix-like systems such as Linux, *BSD and Solaris.
Each ELF file is composed by an ELF Header (metadata) followed by the actual data.

There are three main types of object files:
\begin{itemize}
\item Relocatable files hold code and data suitable for linking with other object files to create an
executable or a shared object file.
\item Executable files hold a program suitable for execution.
\item Shared object files holds code and data suitable for linking in two contexts. First, the link editor may process it with other relocatable and shared object files to create another object file. Second, the dynamic linker combines it with an executable file and other shared objects to create a process image.
\end{itemize}

The loading and execution of a program can be summarized in the following steps:
\begin{enumerate}
\item The \texttt{exec()} system call is called with the path of the executable. The kernel takes control of the execution (\texttt{int \$0x80}) and reads a small subset of the executable's metadata in order to map the executable into memory and the executable's interpreter (typically the RTLD, \texttt{ld.so}) into the process' address space.
\item A context switch into userland is made and the interpreter is started (\texttt{RTLD\_START()} is called in the case of \texttt{ld.so})
\item The interpreter loads all the needed libraries such as \texttt{libc.so} and patches memory as specified by the executable's metadata
\item The execution jumps the executable's entry-point (usually \texttt{\_start})
\end{enumerate}

\subsubsection*{Addresses relocation} 
For our purposes the executable's metadata and the patching of the memory by the interpreter is particularly important, as the weird machine presented in this section is based on those primitives. We will go a bit more in detail in this step.

Unlike executables, when shared libraries are being built, the linker can not assume a known load address for their code. The reason for this is simple: each program can use any number of shared libraries, and there is simply no way to know in advance where any given shared library will be loaded in the process's virtual memory. This problem is solved by the RTLD.

The true entry point of the interpreter is \texttt{\_dl\_start}, this function is called by the kernel from the \texttt{start\_thread()} kernel function. At the end of the dynamic linking process, the starting function of the binary, the \texttt{\_start()} point, is called. \cite{eresi}

It is important to remark that each object in the dynamic linker is described by a \texttt{link\_map} structure. Those structures are only created at runtime and contain different kind of information, such as: the base address at which the ELF object was loaded, the virtual address of all the ELF object's dynamic table entries and pointers to other loaded link map structures. All the link map structures form a doubly linked list so from every structure we can find information on any other loaded ELF object by traversing the list.

Symbols are a way to assign mnemonic names to addresses. ELF provides two different symbol tables: \texttt{.symtab} and \texttt{.dynsym}. \texttt{.dynsym} is just a smaller version of the symtab that only contains global symbols, it contains information required at runtime such as the names of the needed libraries. Symbol metadata is memorized using \texttt{Elf64\_Sym} structures. This kind of metadata is used in the following construction to build registers: symbols with 8 byte values are used, type must be set to \texttt{FUNC} so it is treated as a regular symbol. An example is the following:
\texttt{\{name=foo, value=0xb0000000, type=FUNC, shndx=1, size=8\}}

\texttt{.rela.dyn} and \texttt{.rela.plt} are two tables that contain relocation entries using \texttt{Elf64\_Rela} structures. Relocation entries are used to patch the table with the locations of imported library functions at runtime. The difference between the two tables is that \texttt{.rela.plt} entries are typically processed lazily during dynamic linking while \texttt{.rela.dyn} relocation entries are processed during load time, just before the RTLD passes control to the executable.

Three types of relocation entries are interesting for constructing the weird machine. They are shown in the following table, their behavior is summarized using a C-like code where \texttt{r} is the relocation entry, \texttt{s} is the corresponding symbol and \texttt{base} is the base address of the ELF object.

\begin{tabular}{ l | l }
  \hline
  \texttt{R\_X86\_64\_COPY} (COPY) & \texttt{memcpy(r.offset,s.value,s.size)} \\
  \texttt{R\_X86\_64\_64} (SYM) & \texttt{*(base+r.offset)=s.value+r.addend+base} \\
  \texttt{R\_X86\_64\_RELATIVE} (RELATIVE) & \texttt{*(base+r.offset)=r.addend+base} \\
  \hline
\end{tabular}


\subsection{Weird machine primitives}

The weird machine presented in this section implements a simplified assembly-like language. It offers the following instructions:
\begin{itemize}
\item Move (\texttt{mov})
\item Addition (\texttt{add})
\item Jump-if-not-zero (\texttt{jnz})
\end{itemize}

Accepted input formats for those instructions are the following:
\begin{itemize}
\item Immediate (e.g.: \texttt{\$0x42})
\item Direct, the given location contains the value address (e.g.: \texttt{*0xcafebabe})
\item Register, the given register contains the value (e.g.:\texttt{\%reg})
\item Register indirect, the given register contains the value address (e.g.: \texttt{[\%reg]})
\end{itemize}


\subsubsection{Move}
The \texttt{mov} instruction allows to copy a value from a source to a destination. It is trivial to build a \texttt{mov} instruction using relocation entries of type \texttt{RELATIVE}. The syntax of the instruction is:

\texttt{mov <dest>, <value>}

\texttt{<dest>} has to be passed in direct mode while \texttt{<value>} supports either immediate or register indirect values. The following table shows two examples of the conversion from a \texttt{mov} instruction to relocation metadata.

\begin{tabular}{ l | l }
  \hline
  \texttt{mov *0xbeef0000, \$0x04} & \texttt{\{type=RELATIVE, offset=0xbeef0000, symbol=0,} \\ &  \texttt{addend=0x04\}} \\
  \hline \\
  \texttt{mov *0xbeef0000, [\%foo]} & \texttt{\{type=COPY, offset=0xbeef0000, symbol=foo,} \\ & \texttt{addend=0\}} \\
  \hline
\end{tabular}


\subsubsection{Addition}
The \texttt{add} instruction allows to compute an addition and save the result to a destination. copy a value from a source to a destination. It is again trivial to build a this instruction using \texttt{SYM} relocation entries. The syntax of the instruction is:

\texttt{add <dest>, <addend1>, <addend2>}

\texttt{<dest>} has to be specified as a direct value, \texttt{<addend1>} as a register value, and \texttt{<addend 2>} as an immediate.

The following table shows an example of the conversion from an \texttt{add} instruction to relocation metadata.

\begin{tabular}{ l | l }
  \hline
  \texttt{add *0xbeef0000, \%foo, \$0x02} & \texttt{\{type=SYM, offset=0xbeef0000, symbol=foo,} \\ 
& \texttt{addend=2\}} \\
  \hline
\end{tabular}


\subsubsection{Jump-if-not-zero}
\texttt{jne} instructions allow to transfer the flow of execution to another point of the program. It is not easy to implement jumps using relocation entries, as for their original purpose there is no need for the interpreter to jump between relocation entries.

\paragraph{Building an unconditional jump.}
The processing of relocation addresses by the RTLD can be summarized as follows:
\begin{lstlisting}
while (lm != NULL) {
  r = lm->dyn[DT_RELA];
  end = r + lm->dyn[DT_RELASZ];
  for (; r < end; r++) {
    relocate(lm, r, &dyn[DT_SYM]);
  }
  lm = lm->prev;
}
\end{lstlisting}

The basic idea for building a jump is to modify \texttt{end} in order to exit the "for loop" prematurely without going on processing the following relocation entries, enter in the "while loop" again but starting from a different \texttt{r}.
It is possible to achieve this by exploiting the RTLD behavior. These are the steps that have to be done:

\begin{enumerate}
\item Change \texttt{lm->prev} to point to the same relocation entry, so that the while loop will process it again later (this, in the end, needs to be reset to the original value)
\item Set \texttt{lm->dyn[DT\_RELA]} to point to the relocation entry of the jump destination
\item Set \texttt{lm->dyn[DT\_RELASZ]} to the size of the relocation entries from the jump destination on
\item Change the value of \texttt{end} to exit the for loop
\end{enumerate}

The following table summarizes the process needed to achieve each point.

\begin{longtable}{ l | p{0.75\textwidth} }
  \hline
  1 & A pointer to the \texttt{link\_map} is stored in the Global Offset Table (GOT), whose address is known at compile time. Thus, it is possible to compute the final address of \texttt{prev} and use a \texttt{mov} instruction to overwrite it. \\ & E.g.: \texttt{mov *<addr of prev>, \$<addr of link\_map>} \\ \hline \\
  2-3 & Here there is the requirement of knowing the virtual address of the dynamic table. It is possible to calculate it at compile time and solve again the issues with \texttt{mov} instructions \\ & E.g.: \texttt{mov *(<address of DT\_RELA>), <address of next relocation entry to process>} \\ \hline \\
  4 & \texttt{end} is stored on the stack, if ASLR is on its location is randomized. Luckily the loader stores the address of some stack-allocated data in a statically-allocated variable. We can lookup the base-address of the loader to calculate the location of this static variable. Assuming the
address of \texttt{end} is stored in a symbol called \texttt{sym-end}, the following instructions will set end to 0, forcing the loop to exit prematurely: \\
  & \texttt{mov *<addr of next Rela's offset>, \%sym-end mov *<(value overwritten)>, \$0} \\
  \hline
\end{longtable}

\paragraph{Conditional branch.} To move from an unconditional branch to a conditional one there is the need of a bit more instructions. For this feature we need to exploit the RTLD behavior with \texttt{IFUNC} type symbols. These structures are processed in two different ways, depending on the value of the \texttt{shndx} field. (1) If it is not 0, then the RTLD treats the symbol as an indirect function, calling the function it points to and using the value returned by the indirect function. (2) If the \texttt{shndx} field is zero, then that symbol's value is used directly.
For achieving our goal we need a special symbol (that we call \texttt{sym-zero}) that is of type \texttt{IFUNC} and points to a function that returns zero. Then we need the following instructions:\\
\texttt{mov *<addr of sym-zero shndx>, \$<test val>} \\
\texttt{add *<addr of end>, \%sym-zero, \$0}

In this way if the value being tested is zero, then also \texttt{\%sym-zero} will be treated as zero (because of the \texttt{IFUNC} processing), so \texttt{end} will be zero and the for loop will exit. Otherwise \texttt{end} will be greater than zero and the following instruction, that resets \texttt{end} to its original value, will be executed and the computation will go on without branching.


\subsection{A Turing complete machine inside ELF}

Using the given primitives it is possible to achieve computation using only ELF relocation metadata. No code is injected in the binary, only more ELF headers are added, but still it is possible to execute instructions or modify memory before the actual code is executed. This approach is also robust against ASLR.

The original authors of the paper built a Brainfuck to ELF-metadata compiler to demonstrate how to practically awake the hidden weird machine in the RTLD.

This document will not explain implementation challenges and constraints, but, if the reader is interested, he can go into more detail by reading the original paper. However, here there are some points that is important to keep in mind when implementing this weird machine:
\begin{itemize}
\item For implementing conditional branching there is the need to know the base address of the RTLD. This is not trivial
\item Existing metadata should not be corrupted, we want the final executable to still run as normal
\item The interpreter runs some sanity checks on the metadata, they should not corrupt the weird machine instructions
\end{itemize}


\subsection{Where to go from here?}
This weird machine is heavily dependent upon ELF, probably other executables format can be exploited in the same way. For this reason also PE (Windows) and Mach-O (OSX) are a subject of future research.
The relocation-metadata machine also shows that executable headers must be taken into account when studying the security of a system and are worth to be analyzed in detail by antivirus systems.

To better explain how an attacker could exploit this weird machine the original authors built a root shell backdoor hidden in the relocation metadata of a \texttt{ping} executable. It is important to remark that: 
\begin{itemize}
\item Ping runs with the SUID bit but drops privileges 
\item The optional \texttt{--type} command-line argument is passed to the \texttt{strcasecmp} function.
\end{itemize}

To get ping to execute arbitrary programs as root, we have to insert relocation metadata to override the call to \texttt{setuid()} to not do anything useful (so privileges are not dropped) and the call to \texttt{strcasecmp} to launch a \texttt{execl} instead. It turns out that it can be implemented using nine relocation entries and one symbol table entry and without making any changes to the executable segments of ping.

It is interesting to notice that is possible to achieve this even without all the power of Turing-completeness of the machine, so an attacker might need very little power to exploit weird machines.

\section{Weird machine \#2: Page fault driven computation}
The goal of the weird machine presented in this section is to exploit the MMU to do computation. This suggests that we could consider view the internal logic of page fault and memory translation as the finite automaton of a Turing machine and the memory as holding its "tape", by potentially creating a kind of a closed loop of memory accesses.
Interrupt handling and address translations are controlled using registers and tables. Moreover, when a page fault occurs the information about the trap is saved on the stack. By setting the address of the trap handler to cause another fault we will end up with the processor continuously dispatching page-faults. If the tables controlling this behavior are crafted in the right way, the side effects of the interrupt handling form a Turing-complete one-instruction computer.

\subsection{Introduction to MMU and traps handling}

\subsection{Weird machine primitives}

The unique instruction we want to build is called \texttt{movdbz} that stays for "move-branch-if-zero-or-decrement".

\texttt{movdbz <dest> <source> <branch>}

This construction is proved to be Turing complete, its behavior is summarized in the following list:
\begin{enumerate}
\item \texttt{source} is loaded and decremented
\item if the decrementation did not cause an underflow the result is stored in \texttt{dest} and computation flow goes on to the next instruction
\item otherwise, if the decrementation caused an undeflow, 0 is stored in \texttt{dest} and the program flow jumps to \texttt{branch}
\end{enumerate}

\subsection{A Turing complete machine based on Page Faults}

\subsection{Conclusions}


\section{Comparison of weird machines \#1 and \#2}

\subsection{Advantages of the given constructions}

\subsection{Limitations of the given constructions}



\section{Conclusions}

\begin{thebibliography}{12}
\bibitem{hund} Hund, R., Holz T., Freiling, F. C.: {\sl Return-oriented rootkits: bypassing kernel code integrity protection mechanisms}; In Proceedings of the 18th USENIX Security Symposium (2009), USENIX Association, pp. 383–398.

\bibitem{smashing} Aleph One: {\sl Smashing The Stack For Fun And Profit}; Phrack 49

\bibitem{bratus} S. Bratus, M. E. Locasto, M. L. Patterson, L. Sassaman, A. Shubina: {\sl Exploit Programming From Buffer Overflows to "Weird Machines" and Theory of Computation}

\bibitem{elf_machine} R. Shapiro, S. Bratus, S. W. Smith {\sl "Weird Machines" in ELF: A Spotlight on the Underappreciated Metadata}; WOOT'13 Proceedings of the 7th USENIX conference on Offensive Technologies (2013)

\bibitem{eresi} mayhem: {\sl Understanding Linux ELF RTLD internals}; Phrack 59
\end{thebibliography}
\end{document}

